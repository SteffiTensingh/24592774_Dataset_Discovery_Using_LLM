{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steffi Grace\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Packages Installation\n",
    "import pandas as pd\n",
    "from transformers import Trainer, TrainingArguments, T5ForConditionalGeneration, T5Tokenizer\n",
    "from datasets import load_metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fetching Metadata from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metadata = pd.read_csv(\"E:\\\\Data Science\\\\Research Project\\\\Research_Project\\\\Rough Scripts\\\\MetaData_Cleaned_DS.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed metadata:\n",
      "            owner                      id  \\\n",
      "0     data-ny-gov               thd2-fu8y   \n",
      "1      markmarkoh        coronavirus-data   \n",
      "2    chandrasekar          coronatracking   \n",
      "3  george-t-stagg       cost-benchmarking   \n",
      "4      crawlfeeds  fashion-images-dataset   \n",
      "\n",
      "                                               title  \\\n",
      "0  [nyserda, electric, vehicle, drive, clean, reb...   \n",
      "1                         [coronavirus, daily, data]   \n",
      "2                                   [coronatracking]   \n",
      "3                               [cost, benchmarking]   \n",
      "4                          [fashion, image, dataset]   \n",
      "\n",
      "                                         description  \\\n",
      "0  [new, york, state, charge, ny, initiative, off...   \n",
      "1      [coronoavirus, covid19, data, updated, daily]   \n",
      "2  [adding, public, datasets, related, to, corona...   \n",
      "3  [cost, benchmarking, data, for, the, beverage,...   \n",
      "4                 [fashion, product, image, dataset]   \n",
      "\n",
      "                                             summary  \\\n",
      "0  [original, title, nyserda, electric, vehicle, ...   \n",
      "1  [editormarkdown, originally, sourced, from, sy...   \n",
      "2  [editorsimple, all, data, obtained, from, the,...   \n",
      "3                                              [nan]   \n",
      "4  [editorsimple, fashion, product, image, datase...   \n",
      "\n",
      "                                version  \\\n",
      "0  dab0adef-3132-420e-96da-46d5ed67fd12   \n",
      "1  30a6f17d-2090-48c3-8150-dcc07579d781   \n",
      "2  55a57c94-3c0c-46fc-b05f-f2222620f767   \n",
      "3  4adbb32d-8c55-4fbf-8f70-fcb960b8f0b4   \n",
      "4  83f4476b-6a14-494d-823e-9a94b524c064   \n",
      "\n",
      "                                                tags        license  \\\n",
      "0  ev electric vehicle bev phev ghg drive clean r...          other   \n",
      "1                       coronavirus health virus flu                  \n",
      "2                      corona virus covid19 covid 19                  \n",
      "3                                                                     \n",
      "4  imagesdataset fashion image dataset image dataset  public domain   \n",
      "\n",
      "     visibility                                              files  status  \\\n",
      "0          open  [{'name': 'nyserda-electric-vehicle-drive-clea...  loaded   \n",
      "1          open  [{'name': 'full_data.csv', 'sizeInBytes': 1654...  loaded   \n",
      "2          open  [{'name': 'COVID-19 Cases_tableau.csv', 'sizeI...  loaded   \n",
      "3  discoverable  [{'name': 'Situation Recort Army File (SITRA);...  loaded   \n",
      "4          open  [{'name': 'fashion_product_images.zip', 'sizeI...  loaded   \n",
      "\n",
      "               created              updated accessLevel versionDois  \\\n",
      "0  2020-05-07T10:40:12  2020-10-08T07:21:12        read          []   \n",
      "1  2020-03-12T02:55:16  2020-12-04T15:15:28        read          []   \n",
      "2  2020-03-17T07:59:42  2020-03-19T08:14:11        read          []   \n",
      "3  2020-06-11T02:05:42  2021-05-14T05:29:05    discover          []   \n",
      "4  2021-09-19T06:58:25  2022-08-09T20:08:10        read          []   \n",
      "\n",
      "   isProject                                        assetStatus  \\\n",
      "0      False                                                      \n",
      "1      False                                                      \n",
      "2       True                                                      \n",
      "3      False  {'assetStatusLabel': 'Approved', 'dispositionL...   \n",
      "4      False                                                      \n",
      "\n",
      "                                       properties dois  \\\n",
      "0                                                        \n",
      "1                                                        \n",
      "2                                                        \n",
      "3  {'Impact Potential': 'Impact Testo Michelada'}   []   \n",
      "4                                                   []   \n",
      "\n",
      "                                         dataset_url  \n",
      "0           https://data.world/data-ny-gov/thd2-fu8y  \n",
      "1     https://data.world/markmarkoh/coronavirus-data  \n",
      "2     https://data.world/chandrasekar/coronatracking  \n",
      "3  https://data.world/george-t-stagg/cost-benchma...  \n",
      "4  https://data.world/crawlfeeds/fashion-images-d...  \n"
     ]
    }
   ],
   "source": [
    "def preprocess_metadata(metadata):\n",
    "    # Clean text data (e.g., remove special characters, lowercase)\n",
    "    cleaned_metadata = metadata.copy() \n",
    "    cleaned_metadata['description'] = cleaned_metadata['description'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', str(x)))\n",
    "    cleaned_metadata['description'] = cleaned_metadata['description'].str.lower()\n",
    "    cleaned_metadata['title'] = cleaned_metadata['title'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', str(x)))\n",
    "    cleaned_metadata['title'] = cleaned_metadata['title'].str.lower()\n",
    "    cleaned_metadata['summary'] = cleaned_metadata['summary'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', str(x)))\n",
    "    cleaned_metadata['summary'] = cleaned_metadata['summary'].str.lower()\n",
    "\n",
    "    \n",
    "    # Tokenize text data (split into words)\n",
    "    cleaned_metadata['description'] = cleaned_metadata['description'].str.split()        \n",
    "    cleaned_metadata['title'] = cleaned_metadata['title'].str.split()        \n",
    "    cleaned_metadata['summary'] = cleaned_metadata['summary'].str.split()\n",
    "\n",
    "    # Handle missing values (e.g., fill with a placeholder or remove rows)\n",
    "    cleaned_metadata.fillna('', inplace=True)\n",
    "    \n",
    "    return cleaned_metadata\n",
    "\n",
    "# Preprocess metadata\n",
    "Preprocess_Metadata = preprocess_metadata(Metadata)\n",
    "\n",
    "print(\"Preprocessed metadata:\")\n",
    "print(Preprocess_Metadata.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocess_Metadata = preprocess_metadata(Metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast  # Module for literal string evaluation\n",
    "\n",
    "Preprocess_Metadata['files'] = Preprocess_Metadata['files'].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract file formats\n",
    "def extract_formats(files):\n",
    "    formats = set()\n",
    "    for file in files:\n",
    "        filename = file['name']\n",
    "        file_format = filename.split('.')[-1]\n",
    "        formats.add(file_format)\n",
    "    return list(formats)\n",
    "\n",
    "    # Apply function to create new column\n",
    "Preprocess_Metadata['available_formats'] = Preprocess_Metadata['files'].apply(extract_formats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owner</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>summary</th>\n",
       "      <th>version</th>\n",
       "      <th>tags</th>\n",
       "      <th>license</th>\n",
       "      <th>visibility</th>\n",
       "      <th>files</th>\n",
       "      <th>...</th>\n",
       "      <th>created</th>\n",
       "      <th>updated</th>\n",
       "      <th>accessLevel</th>\n",
       "      <th>versionDois</th>\n",
       "      <th>isProject</th>\n",
       "      <th>assetStatus</th>\n",
       "      <th>properties</th>\n",
       "      <th>dois</th>\n",
       "      <th>dataset_url</th>\n",
       "      <th>available_formats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data-ny-gov</td>\n",
       "      <td>thd2-fu8y</td>\n",
       "      <td>[nyserda, electric, vehicle, drive, clean, reb...</td>\n",
       "      <td>[new, york, state, charge, ny, initiative, off...</td>\n",
       "      <td>[original, title, nyserda, electric, vehicle, ...</td>\n",
       "      <td>dab0adef-3132-420e-96da-46d5ed67fd12</td>\n",
       "      <td>ev electric vehicle bev phev ghg drive clean r...</td>\n",
       "      <td>other</td>\n",
       "      <td>open</td>\n",
       "      <td>[{'name': 'nyserda-electric-vehicle-drive-clea...</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-05-07T10:40:12</td>\n",
       "      <td>2020-10-08T07:21:12</td>\n",
       "      <td>read</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://data.world/data-ny-gov/thd2-fu8y</td>\n",
       "      <td>[csv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>markmarkoh</td>\n",
       "      <td>coronavirus-data</td>\n",
       "      <td>[coronavirus, daily, data]</td>\n",
       "      <td>[coronoavirus, covid19, data, updated, daily]</td>\n",
       "      <td>[editormarkdown, originally, sourced, from, sy...</td>\n",
       "      <td>30a6f17d-2090-48c3-8150-dcc07579d781</td>\n",
       "      <td>coronavirus health virus flu</td>\n",
       "      <td></td>\n",
       "      <td>open</td>\n",
       "      <td>[{'name': 'full_data.csv', 'sizeInBytes': 1654...</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-03-12T02:55:16</td>\n",
       "      <td>2020-12-04T15:15:28</td>\n",
       "      <td>read</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://data.world/markmarkoh/coronavirus-data</td>\n",
       "      <td>[csv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chandrasekar</td>\n",
       "      <td>coronatracking</td>\n",
       "      <td>[coronatracking]</td>\n",
       "      <td>[adding, public, datasets, related, to, corona...</td>\n",
       "      <td>[editorsimple, all, data, obtained, from, the,...</td>\n",
       "      <td>55a57c94-3c0c-46fc-b05f-f2222620f767</td>\n",
       "      <td>corona virus covid19 covid 19</td>\n",
       "      <td></td>\n",
       "      <td>open</td>\n",
       "      <td>[{'name': 'COVID-19 Cases_tableau.csv', 'sizeI...</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-03-17T07:59:42</td>\n",
       "      <td>2020-03-19T08:14:11</td>\n",
       "      <td>read</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://data.world/chandrasekar/coronatracking</td>\n",
       "      <td>[csv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>george-t-stagg</td>\n",
       "      <td>cost-benchmarking</td>\n",
       "      <td>[cost, benchmarking]</td>\n",
       "      <td>[cost, benchmarking, data, for, the, beverage,...</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>4adbb32d-8c55-4fbf-8f70-fcb960b8f0b4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>discoverable</td>\n",
       "      <td>[{'name': 'Situation Recort Army File (SITRA);...</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-06-11T02:05:42</td>\n",
       "      <td>2021-05-14T05:29:05</td>\n",
       "      <td>discover</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>{'assetStatusLabel': 'Approved', 'dispositionL...</td>\n",
       "      <td>{'Impact Potential': 'Impact Testo Michelada'}</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://data.world/george-t-stagg/cost-benchma...</td>\n",
       "      <td>[csv, xlsx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crawlfeeds</td>\n",
       "      <td>fashion-images-dataset</td>\n",
       "      <td>[fashion, image, dataset]</td>\n",
       "      <td>[fashion, product, image, dataset]</td>\n",
       "      <td>[editorsimple, fashion, product, image, datase...</td>\n",
       "      <td>83f4476b-6a14-494d-823e-9a94b524c064</td>\n",
       "      <td>imagesdataset fashion image dataset image dataset</td>\n",
       "      <td>public domain</td>\n",
       "      <td>open</td>\n",
       "      <td>[{'name': 'fashion_product_images.zip', 'sizeI...</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-09-19T06:58:25</td>\n",
       "      <td>2022-08-09T20:08:10</td>\n",
       "      <td>read</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>https://data.world/crawlfeeds/fashion-images-d...</td>\n",
       "      <td>[zip]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>sports</td>\n",
       "      <td>recognized-sports</td>\n",
       "      <td>[recognized, sport]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[here, is, a, list, of, international, sport, ...</td>\n",
       "      <td>bbe67446-52cf-4668-aa13-4cf2650f8eb4</td>\n",
       "      <td>sport official sport list of sport type of sport</td>\n",
       "      <td></td>\n",
       "      <td>open</td>\n",
       "      <td>[{'name': 'recognized_sports.xlsx', 'sizeInByt...</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-04-14T19:16:03</td>\n",
       "      <td>2017-12-20T19:28:57</td>\n",
       "      <td>read</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://data.world/sports/recognized-sports</td>\n",
       "      <td>[xlsx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>crowdflower</td>\n",
       "      <td>sports-illustrated-covers</td>\n",
       "      <td>[sport, illustrated, cover]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[a, data, set, listing, the, sport, that, have...</td>\n",
       "      <td>756db1e6-2b6e-4827-869d-907036b57ebe</td>\n",
       "      <td>crowdsourced sport magazine cover image photo ...</td>\n",
       "      <td>public domain</td>\n",
       "      <td>open</td>\n",
       "      <td>[{'name': 'SI-Cover-by-Sport-DFE.csv', 'sizeIn...</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-11-21T23:43:16</td>\n",
       "      <td>2016-11-21T23:51:17</td>\n",
       "      <td>read</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://data.world/crowdflower/sports-illustra...</td>\n",
       "      <td>[csv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>the-pudding</td>\n",
       "      <td>winningest-cities-in-sports</td>\n",
       "      <td>[winningest, city, in, sport]</td>\n",
       "      <td>[data, for, every, championship, win, in, six,...</td>\n",
       "      <td>[editormarkdown, about, this, dataset, contain...</td>\n",
       "      <td>e6a36707-1abc-41e8-9ff4-6f9ba76b67d1</td>\n",
       "      <td>sport championship ranking basketball football...</td>\n",
       "      <td>other</td>\n",
       "      <td>open</td>\n",
       "      <td>[{'name': 'case1.json', 'sizeInBytes': 126097,...</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-03-10T19:54:14</td>\n",
       "      <td>2021-07-15T01:42:48</td>\n",
       "      <td>read</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>https://data.world/the-pudding/winningest-citi...</td>\n",
       "      <td>[json, csv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>datagov-uk</td>\n",
       "      <td>17c44e3a-804c-487b-a07f-b90298685e2a</td>\n",
       "      <td>[thurrock, outdoor, sport]</td>\n",
       "      <td>[thurrock, outdoor, sport]</td>\n",
       "      <td>[this, dataset, show, the, location, of, outdo...</td>\n",
       "      <td>21708327-0e5c-4725-8bba-e4f616c8454c</td>\n",
       "      <td></td>\n",
       "      <td>ogl</td>\n",
       "      <td>open</td>\n",
       "      <td>[{'name': 'tc-outdoor-sports-1.xml', 'sizeInBy...</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-08-26T08:50:00</td>\n",
       "      <td>2021-08-26T08:50:06</td>\n",
       "      <td>read</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://data.world/datagov-uk/17c44e3a-804c-48...</td>\n",
       "      <td>[xml]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>zendoll27</td>\n",
       "      <td>trends-in-youth-sports</td>\n",
       "      <td>[trend, in, youth, sport]</td>\n",
       "      <td>[aspen, institute, 2019, trend, in, youth, spo...</td>\n",
       "      <td>[editorsimple, original, data, source]</td>\n",
       "      <td>2ec69f50-1aa5-4958-a374-02616ffe5393</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>open</td>\n",
       "      <td>[{'name': 'Trends in Youth Sports.xlsx', 'size...</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-12-02T13:29:06</td>\n",
       "      <td>2021-12-06T15:05:35</td>\n",
       "      <td>read</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>https://data.world/zendoll27/trends-in-youth-s...</td>\n",
       "      <td>[xlsx]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             owner                                    id  \\\n",
       "0      data-ny-gov                             thd2-fu8y   \n",
       "1       markmarkoh                      coronavirus-data   \n",
       "2     chandrasekar                        coronatracking   \n",
       "3   george-t-stagg                     cost-benchmarking   \n",
       "4       crawlfeeds                fashion-images-dataset   \n",
       "..             ...                                   ...   \n",
       "64          sports                     recognized-sports   \n",
       "65     crowdflower             sports-illustrated-covers   \n",
       "66     the-pudding           winningest-cities-in-sports   \n",
       "67      datagov-uk  17c44e3a-804c-487b-a07f-b90298685e2a   \n",
       "68       zendoll27                trends-in-youth-sports   \n",
       "\n",
       "                                                title  \\\n",
       "0   [nyserda, electric, vehicle, drive, clean, reb...   \n",
       "1                          [coronavirus, daily, data]   \n",
       "2                                    [coronatracking]   \n",
       "3                                [cost, benchmarking]   \n",
       "4                           [fashion, image, dataset]   \n",
       "..                                                ...   \n",
       "64                                [recognized, sport]   \n",
       "65                        [sport, illustrated, cover]   \n",
       "66                      [winningest, city, in, sport]   \n",
       "67                         [thurrock, outdoor, sport]   \n",
       "68                          [trend, in, youth, sport]   \n",
       "\n",
       "                                          description  \\\n",
       "0   [new, york, state, charge, ny, initiative, off...   \n",
       "1       [coronoavirus, covid19, data, updated, daily]   \n",
       "2   [adding, public, datasets, related, to, corona...   \n",
       "3   [cost, benchmarking, data, for, the, beverage,...   \n",
       "4                  [fashion, product, image, dataset]   \n",
       "..                                                ...   \n",
       "64                                              [nan]   \n",
       "65                                              [nan]   \n",
       "66  [data, for, every, championship, win, in, six,...   \n",
       "67                         [thurrock, outdoor, sport]   \n",
       "68  [aspen, institute, 2019, trend, in, youth, spo...   \n",
       "\n",
       "                                              summary  \\\n",
       "0   [original, title, nyserda, electric, vehicle, ...   \n",
       "1   [editormarkdown, originally, sourced, from, sy...   \n",
       "2   [editorsimple, all, data, obtained, from, the,...   \n",
       "3                                               [nan]   \n",
       "4   [editorsimple, fashion, product, image, datase...   \n",
       "..                                                ...   \n",
       "64  [here, is, a, list, of, international, sport, ...   \n",
       "65  [a, data, set, listing, the, sport, that, have...   \n",
       "66  [editormarkdown, about, this, dataset, contain...   \n",
       "67  [this, dataset, show, the, location, of, outdo...   \n",
       "68             [editorsimple, original, data, source]   \n",
       "\n",
       "                                 version  \\\n",
       "0   dab0adef-3132-420e-96da-46d5ed67fd12   \n",
       "1   30a6f17d-2090-48c3-8150-dcc07579d781   \n",
       "2   55a57c94-3c0c-46fc-b05f-f2222620f767   \n",
       "3   4adbb32d-8c55-4fbf-8f70-fcb960b8f0b4   \n",
       "4   83f4476b-6a14-494d-823e-9a94b524c064   \n",
       "..                                   ...   \n",
       "64  bbe67446-52cf-4668-aa13-4cf2650f8eb4   \n",
       "65  756db1e6-2b6e-4827-869d-907036b57ebe   \n",
       "66  e6a36707-1abc-41e8-9ff4-6f9ba76b67d1   \n",
       "67  21708327-0e5c-4725-8bba-e4f616c8454c   \n",
       "68  2ec69f50-1aa5-4958-a374-02616ffe5393   \n",
       "\n",
       "                                                 tags        license  \\\n",
       "0   ev electric vehicle bev phev ghg drive clean r...          other   \n",
       "1                        coronavirus health virus flu                  \n",
       "2                       corona virus covid19 covid 19                  \n",
       "3                                                                      \n",
       "4   imagesdataset fashion image dataset image dataset  public domain   \n",
       "..                                                ...            ...   \n",
       "64   sport official sport list of sport type of sport                  \n",
       "65  crowdsourced sport magazine cover image photo ...  public domain   \n",
       "66  sport championship ranking basketball football...          other   \n",
       "67                                                               ogl   \n",
       "68                                                                     \n",
       "\n",
       "      visibility                                              files  ...  \\\n",
       "0           open  [{'name': 'nyserda-electric-vehicle-drive-clea...  ...   \n",
       "1           open  [{'name': 'full_data.csv', 'sizeInBytes': 1654...  ...   \n",
       "2           open  [{'name': 'COVID-19 Cases_tableau.csv', 'sizeI...  ...   \n",
       "3   discoverable  [{'name': 'Situation Recort Army File (SITRA);...  ...   \n",
       "4           open  [{'name': 'fashion_product_images.zip', 'sizeI...  ...   \n",
       "..           ...                                                ...  ...   \n",
       "64          open  [{'name': 'recognized_sports.xlsx', 'sizeInByt...  ...   \n",
       "65          open  [{'name': 'SI-Cover-by-Sport-DFE.csv', 'sizeIn...  ...   \n",
       "66          open  [{'name': 'case1.json', 'sizeInBytes': 126097,...  ...   \n",
       "67          open  [{'name': 'tc-outdoor-sports-1.xml', 'sizeInBy...  ...   \n",
       "68          open  [{'name': 'Trends in Youth Sports.xlsx', 'size...  ...   \n",
       "\n",
       "                created              updated accessLevel versionDois  \\\n",
       "0   2020-05-07T10:40:12  2020-10-08T07:21:12        read          []   \n",
       "1   2020-03-12T02:55:16  2020-12-04T15:15:28        read          []   \n",
       "2   2020-03-17T07:59:42  2020-03-19T08:14:11        read          []   \n",
       "3   2020-06-11T02:05:42  2021-05-14T05:29:05    discover          []   \n",
       "4   2021-09-19T06:58:25  2022-08-09T20:08:10        read          []   \n",
       "..                  ...                  ...         ...         ...   \n",
       "64  2017-04-14T19:16:03  2017-12-20T19:28:57        read          []   \n",
       "65  2016-11-21T23:43:16  2016-11-21T23:51:17        read          []   \n",
       "66  2019-03-10T19:54:14  2021-07-15T01:42:48        read          []   \n",
       "67  2021-08-26T08:50:00  2021-08-26T08:50:06        read          []   \n",
       "68  2021-12-02T13:29:06  2021-12-06T15:05:35        read          []   \n",
       "\n",
       "   isProject                                        assetStatus  \\\n",
       "0      False                                                      \n",
       "1      False                                                      \n",
       "2       True                                                      \n",
       "3      False  {'assetStatusLabel': 'Approved', 'dispositionL...   \n",
       "4      False                                                      \n",
       "..       ...                                                ...   \n",
       "64     False                                                      \n",
       "65     False                                                      \n",
       "66     False                                                      \n",
       "67     False                                                      \n",
       "68     False                                                      \n",
       "\n",
       "                                        properties dois  \\\n",
       "0                                                         \n",
       "1                                                         \n",
       "2                                                         \n",
       "3   {'Impact Potential': 'Impact Testo Michelada'}   []   \n",
       "4                                                    []   \n",
       "..                                             ...  ...   \n",
       "64                                                        \n",
       "65                                                        \n",
       "66                                                   []   \n",
       "67                                                        \n",
       "68                                                   []   \n",
       "\n",
       "                                          dataset_url available_formats  \n",
       "0            https://data.world/data-ny-gov/thd2-fu8y             [csv]  \n",
       "1      https://data.world/markmarkoh/coronavirus-data             [csv]  \n",
       "2      https://data.world/chandrasekar/coronatracking             [csv]  \n",
       "3   https://data.world/george-t-stagg/cost-benchma...       [csv, xlsx]  \n",
       "4   https://data.world/crawlfeeds/fashion-images-d...             [zip]  \n",
       "..                                                ...               ...  \n",
       "64        https://data.world/sports/recognized-sports            [xlsx]  \n",
       "65  https://data.world/crowdflower/sports-illustra...             [csv]  \n",
       "66  https://data.world/the-pudding/winningest-citi...       [json, csv]  \n",
       "67  https://data.world/datagov-uk/17c44e3a-804c-48...             [xml]  \n",
       "68  https://data.world/zendoll27/trends-in-youth-s...            [xlsx]  \n",
       "\n",
       "[69 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Preprocess_Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Preprocess_Metadata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, list):\n",
    "        # Convert list of strings to a single string\n",
    "        text = ' '.join(text)\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove punctuation and non-alphabetic characters, and single character tokens\n",
    "    tokens = [re.sub(r'[^a-zA-Z]', '', token) for token in tokens if token.isalpha() and len(token) > 1]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Lemmatize tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 relevant dataset URLs with similarity scores:\n",
      "URL: https://data.world/chandrasekar/coronatracking, Similarity Score: 0.2134654546451647\n",
      "URL: https://data.world/rtekumalla1/a-twitter-dataset-of-100-million-tweets-related-to-covid-19, Similarity Score: 0.0693991457338\n",
      "URL: https://data.world/kongkei/buy-wireless-security-cameras-at-affordable-prices, Similarity Score: 0.047899412887408045\n",
      "URL: https://data.world/zendoll27/trends-in-youth-sports, Similarity Score: 0.0\n",
      "URL: https://data.world/healthdatany/h55x-hu6n, Similarity Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "dataset = Preprocess_Metadata.copy()\n",
    "\n",
    "# Apply preprocessing to text columns\n",
    "for column in ['title', 'description', 'summary']:\n",
    "    dataset[column] = dataset[column].apply(preprocess_text)\n",
    "\n",
    "# Prepare the User Input\n",
    "user_input = \"Corona Virus Pandemic\"\n",
    "preprocessed_user_input = preprocess_text(user_input)\n",
    "\n",
    "# Generate Relevance Scores\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(dataset['title'] + ' ' + dataset['description'] + ' ' + dataset['summary'])\n",
    "user_input_vector = tfidf_vectorizer.transform([preprocessed_user_input])\n",
    "cosine_similarities = cosine_similarity(user_input_vector, tfidf_matrix)\n",
    "\n",
    "# Get indices of top 5 relevant dataset URLs\n",
    "top_indices = cosine_similarities.argsort()[0][-5:][::-1]\n",
    "\n",
    "# Get top 5 relevant dataset URLs and their similarity scores\n",
    "top_dataset_urls = dataset.iloc[top_indices]['dataset_url']\n",
    "top_similarity_scores = cosine_similarities[0][top_indices]\n",
    "\n",
    "print(\"Top 5 relevant dataset URLs with similarity scores:\")\n",
    "for url, score in zip(top_dataset_urls, top_similarity_scores):\n",
    "    print(f\"URL: {url}, Similarity Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant dataset URLs above similarity threshold:\n",
      "URL: https://data.world/datagov-uk/3768fd01-2fa1-4514-82d4-ced4aad3e3e5, Similarity Score: 0.4380564269264124\n"
     ]
    }
   ],
   "source": [
    "    import pandas as pd\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "    dataset = Preprocess_Metadata.copy()\n",
    "\n",
    "    # Apply preprocessing to text columns\n",
    "    for column in ['title', 'description', 'summary']:\n",
    "        dataset[column] = dataset[column].apply(preprocess_text)\n",
    "\n",
    "    # Prepare the User Input\n",
    "    user_input = \"Expenditure\"\n",
    "    preprocessed_user_input = preprocess_text(user_input)\n",
    "\n",
    "    # Generate Relevance Scores\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(dataset['title'] + ' ' + dataset['description'] + ' ' + dataset['summary'])\n",
    "    user_input_vector = tfidf_vectorizer.transform([preprocessed_user_input])\n",
    "    cosine_similarities = cosine_similarity(user_input_vector, tfidf_matrix)\n",
    "\n",
    "    # Define similarity threshold\n",
    "    similarity_threshold = 0.06\n",
    "\n",
    "    # Get indices of relevant dataset URLs above the threshold\n",
    "    relevant_indices = [i for i, score in enumerate(cosine_similarities[0]) if score > similarity_threshold]\n",
    "\n",
    "    # Get relevant dataset URLs and their similarity scores\n",
    "    relevant_dataset_urls = dataset.iloc[relevant_indices]['dataset_url']\n",
    "    relevant_similarity_scores = cosine_similarities[0][relevant_indices]\n",
    "\n",
    "    print(\"Relevant dataset URLs above similarity threshold:\")\n",
    "    for url, score in zip(relevant_dataset_urls, relevant_similarity_scores):\n",
    "        print(f\"URL: {url}, Similarity Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess_text_ignoring_common_words(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove punctuation, non-alphabetic characters, and single character tokens\n",
    "    tokens = [re.sub(r'[^a-zA-Z]', '', token) for token in tokens if token.isalpha() and len(token) > 1]\n",
    "    \n",
    "    # Remove stopwords and common words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    common_words = set(['datasets', 'data','repo','repositories','sources','data sources','database'])  # Define common words to remove\n",
    "    tokens = [token for token in tokens if token not in stop_words and token not in common_words]\n",
    "    \n",
    "    # Lemmatize tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant dataset URLs above similarity threshold (arranged in bands based on similarity score):\n",
      "\n",
      "Band 3: Similarity Score Range: 0.27 - 0.34\n",
      "\n",
      "URL: https://data.world/nhtsa/cars-purchased-vehicles-xls, Similarity Score: 0.3445352265372441, Available Formats: ['zip', 'xls']\n",
      "URL: https://data.world/data-ny-gov/thd2-fu8y, Similarity Score: 0.3312246655689556, Available Formats: ['csv']\n",
      "\n",
      "Band 2: Similarity Score Range: 0.19 - 0.27\n",
      "\n",
      "\n",
      "Band 1: Similarity Score Range: 0.12 - 0.19\n",
      "\n",
      "URL: https://data.world/us-epa-gov/124206c8-26a9-435b-9f6c-7cb0d830fbc2, Similarity Score: 0.1165826517390954, Available Formats: ['xml']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "dataset = Preprocess_Metadata.copy()\n",
    "\n",
    "# Apply preprocessing to text columns\n",
    "for column in ['title', 'description', 'summary']:\n",
    "    dataset[column] = dataset[column].apply(preprocess_text)\n",
    "\n",
    "# Prepare the User Input\n",
    "user_input = \"Electric vehicles\"\n",
    "preprocessed_user_input = preprocess_text_ignoring_common_words(user_input)\n",
    "\n",
    "# Generate Relevance Scores\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(dataset['title'] + ' ' + dataset['description'] + ' ' + dataset['summary'])\n",
    "user_input_vector = tfidf_vectorizer.transform([preprocessed_user_input])\n",
    "cosine_similarities = cosine_similarity(user_input_vector, tfidf_matrix)\n",
    "\n",
    "# Define similarity threshold\n",
    "similarity_threshold = 0.0\n",
    "\n",
    "# Get indices of relevant dataset URLs above the threshold\n",
    "relevant_indices = [i for i, score in enumerate(cosine_similarities[0]) if score > similarity_threshold]\n",
    "\n",
    "# Get relevant dataset URLs and their similarity scores\n",
    "relevant_dataset_urls = dataset.iloc[relevant_indices]['dataset_url']\n",
    "relevant_similarity_scores = cosine_similarities[0][relevant_indices]\n",
    "\n",
    "# Calculate min and max similarity scores\n",
    "min_score = min(relevant_similarity_scores)\n",
    "max_score = max(relevant_similarity_scores)\n",
    "\n",
    "# Determine number of bands\n",
    "num_outputs = len(relevant_dataset_urls)\n",
    "num_bands = min(num_outputs, 3) \n",
    "\n",
    "# Divide similarity score range into bands\n",
    "score_bands = [min_score + i * (max_score - min_score) / num_bands for i in range(num_bands)] + [max_score]\n",
    "\n",
    "# Sort relevant dataset URLs and similarity scores by similarity score in descending order\n",
    "sorted_indices = relevant_similarity_scores.argsort()[::-1]\n",
    "sorted_relevant_dataset_urls = relevant_dataset_urls.iloc[sorted_indices]\n",
    "sorted_relevant_similarity_scores = relevant_similarity_scores[sorted_indices]\n",
    "\n",
    "print(\"Relevant dataset URLs above similarity threshold (arranged in bands based on similarity score):\")\n",
    "for i in reversed(range(num_bands)):\n",
    "    band_start = score_bands[i]\n",
    "    band_end = score_bands[i + 1]\n",
    "    print(f\"\\nBand {i+1}: Similarity Score Range: {band_start:.2f} - {band_end:.2f}\\n\")\n",
    "    for url, score in zip(sorted_relevant_dataset_urls, sorted_relevant_similarity_scores):\n",
    "        if band_start <= score <= band_end:\n",
    "            index = dataset[dataset['dataset_url'] == url].index[0]  # Find index of dataset\n",
    "            available_formats = dataset.at[index, 'available_formats']  # Get available formats\n",
    "            print(f\"URL: {url}, Similarity Score: {score}, Available Formats: {available_formats}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
