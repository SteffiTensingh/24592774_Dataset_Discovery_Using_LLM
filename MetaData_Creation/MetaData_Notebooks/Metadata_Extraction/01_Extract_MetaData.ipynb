{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def Fetch_MetaData(DataSet_URL):\n",
    "    # Providing the API URL to \n",
    "    api_url = f\"https://api.data.world/v0/datasets/{DataSet_URL}\"\n",
    "    \n",
    "    # Set the generated API Key to read the metadata\n",
    "    api_token = \"eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OnN0ZWZmaTEwc2luZ2giLCJpc3MiOiJhZ2VudDpzdGVmZmkxMHNpbmdoOjo4ZDJkMjQ4MC04NzMxLTRmM2MtYTc3Mi1mN2FiZTNlNzUyOTUiLCJpYXQiOjE3MTE3MTIwODksInJvbGUiOlsidXNlcl9hcGlfcmVhZCIsInVzZXJfYXBpX3dyaXRlIl0sImdlbmVyYWwtcHVycG9zZSI6dHJ1ZSwic2FtbCI6e319.TC0Hk6lASv4bzo3_RThoQ1rLXYbnXNeT6xDGyg2WYfNKim53FQu7G4-4TsSbvSDtt0AQfKRgMVvL5JCHe454jQ\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_token}\"\n",
    "    }\n",
    "    \n",
    "    # Get request for API end point\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Fetching the Metadata\n",
    "        metadata = response.json()\n",
    "        return metadata\n",
    "    else:\n",
    "        print(f\"Failed to retrieve metadata for dataset: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # Inputing the dataset urls\n",
    "    dataset_urls = [\n",
    "        \"makeovermonday/2023w7\",\"smartcolumbusos/650b7e59-afd3-4c40-9bfc-8d614610b77b\",\n",
    "        \"ohnsnowlabs/electric-vehicle-charging-network\",\"townofcary/electric-vehicle-charging-stations\",\n",
    "        \"data-ny-gov/thd2-fu8y\",\"us-doe-gov/8ae7e117-313b-40b1-b146-83add97d400b\",\n",
    "        \"jeffgswanson/electric-vehicle-by-year\",\"us-doe-gov/3f032a3c-7dc0-4f54-9f51-534b2e248f80\",\n",
    "        \"us-epa-gov/f3822503-5d5e-4cac-ab1c-c8c18847bc7e\",\"datagov-uk/38345f02-0437-434b-937f-921f1494362a\",\n",
    "        \"johnsnowlabs/hawaii-public-electric-vehicle-charging-stations\",\"datagov-uk/e865fb83-66fb-4b5e-a95e-cfbb68a7beb5\",\n",
    "        \"john-rager/nys-electric-vehicles-data\",\"smart-columbus/ff632a3a-64a1-4ba7-babb-86c228c33a0e\",\n",
    "        \"us-nasa-gov/10aa19c8-b795-4520-9502-2793bd8ab6fe\",\"romanian-data/romanian-new-car-registration-in-2023\",\n",
    "        \"rajanand/crime-in-india\",\n",
    "        \"markmarkoh/coronavirus-data\",\n",
    "        \"chandrasekar/coronatracking\",\n",
    "        \"george-t-stagg/cost-benchmarking\",\n",
    "        \"crawlfeeds/fashion-images-dataset\",\n",
    "        \"hdx/e66dbc70-17fe-4230-b9d6-855d192fc05c\",\n",
    "        \"us-doi-gov/12749821-f445-4f35-8dee-81eb7a56f07d\",\n",
    "        \"rtekumalla1/a-twitter-dataset-of-100-million-tweets-related-to-covid-19\",\n",
    "        \"us-nasa-gov/47e3817a-65aa-4af4-8d40-f0ed0f655bda\",\n",
    "        \"us-epa-gov/04e33075-3db2-4e0d-9ecc-009280a2e54a\",\n",
    "        \"nhtsa/cars-purchased-vehicles-xls\",\n",
    "        # XLS\n",
    "        \"brianray/un-births-xls-858-kb\",\n",
    "        \"brianray/un-population-density-xls-3\",\n",
    "        \"brianray/un-net-migration-rate-xls-2\",\n",
    "        \"brianray/un-population-growth-rate-xl\",\n",
    "        # XML\n",
    "        \"us-epa-gov/7780ad55-e259-49fe-a998-990202a4dda1\",\n",
    "        \"okgoogleassistant/okgoogleassistant\",\n",
    "        # AVRO\n",
    "        \"kgs1/test1234\",\n",
    "        # SQLite \n",
    "        \"eng/imdb-movies\",\n",
    "        \"h0tftw/legalmap\",\n",
    "        \"safiat/exemple\",\n",
    "        # CSV\n",
    "        \"datagov-uk/0cd0d5c0-f170-4899-ba45-e7d227bbd0e4\",\n",
    "        # Environment\n",
    "        \"datagov-uk/85074ea3-5e20-488f-86a3-0a9b618e44dc\",\n",
    "        \"datagov-uk/beb955e0-9026-4637-844e-0d70d4ba7638\",\n",
    "        \"datagov-uk/27c88b01-ecba-42d6-abfb-bbdbf911cc5b\",\n",
    "        \"healthdatany/h55x-hu6n\",\n",
    "        # Pollution\n",
    "        \"datagov-uk/85626c92-96ae-477b-aa20-7474d6e7daaf\",\n",
    "        \"us-epa-gov/124206c8-26a9-435b-9f6c-7cb0d830fbc2\",\n",
    "        \"datagov-uk/f32b5948-83a7-4739-9f9d-7d654b31e8ff\",\n",
    "        # Health care\n",
    "        \"chhs/bcc3e8ec-69f2-4bd2-b215-7664cb8eb720\",\n",
    "        \"nrippner/cancer-trials\",\n",
    "        \"cytotecpillsdubai/abortion-pills-price-in-dubai-00971551624914-abortion-pills\",\n",
    "        # Public Health\n",
    "        \"datagov-uk/a9ea9ea0-b8a7-459a-b1d0-0dd0754d63af\",\n",
    "        \"us-hhs-gov/5d067d7b-1b3d-4357-8fe3-a4a63401cb27\",\n",
    "        \"datagov-uk/c445a37f-401f-4361-8ce9-1b79ce3cf57d\",\n",
    "        \"us-hhs-gov/4526c9b9-4000-4b2c-a792-6fd4056fc53a\",\n",
    "        # Social Sciences\n",
    "        \"datagov-uk/297027e8-3297-40e2-8a12-c7c9c124dc0b\",\n",
    "        \"liz-friedman/general-social-survey-data-on-policing-1972-2018\",\n",
    "        # Finance\n",
    "        \"finance/ifc-enterprise-finance-raw\",\n",
    "        \"codefordc/campaign-finance\",\n",
    "        \"datagov-uk/de532aed-869a-4bb6-9bcf-ecf9f5486a48\",\n",
    "        \"datagov-uk/3768fd01-2fa1-4514-82d4-ced4aad3e3e5\",\n",
    "        # Technology\n",
    "        \"datagov-uk/eb673e35-1a59-47d3-b5f1-914a67d85baf\",\n",
    "        \"kongkei/buy-wireless-security-cameras-at-affordable-prices\",\n",
    "        \"freemotion/which-iptv-subscription-service-should-you-go-for\",\n",
    "        # Engineering\n",
    "        \"smartcolumbusos/0d19c53a-e0a8-4bc4-94ca-300b956756f2\",\n",
    "        \"us-nasa-gov/8f4b3f7a-a44b-42c3-b11e-09f7e2c96edd\",\n",
    "        \"us-nasa-gov/12ca296c-38fb-4b24-a6b6-a3b5ed1c1eb5\",\n",
    "        # Food\n",
    "        \"durhamnc/food-health-inspection-data\",\n",
    "        \"datafiniti/food-ingredient-lists\",\n",
    "        \"usda/food-availability-eggs\",\n",
    "        \"datagov-uk/49f680f8-282b-4044-b156-14116bc68367\",\n",
    "        \"agriculture/food-price-outlook\",\n",
    "        # Agriculture \n",
    "        \"us-nasa-gov/5a032816-19de-4236-96f2-968ec4fb699b\",\n",
    "        \"dcopendata/0db40814c3e443e4aee240c3978cc351-52\",\n",
    "        \"agriculture/food-environment-atlas\",\n",
    "        # Arts\n",
    "        \"sanfrancisco/mxvq-mfs5\",\n",
    "        \"city-of-ny/njjd-3gve\",\n",
    "        \"city-of-ny/9h53-fsqa\",\n",
    "        \"city-of-ny/vhtt-kpwy\",\n",
    "        # Culture\n",
    "        \"city-of-tempe/fb968ad6-a58f-41ca-b1fe-cb4ad773f4ee\",\n",
    "        \"makeovermonday/2020w41-data-assets-and-data-culture\",\n",
    "        \"telangana/tourism-and-culture\",\n",
    "        \"us-nasa-gov/b537a76e-fdf3-4988-983b-6fd6a47ccd84\",\n",
    "        # Sports\n",
    "        \"sports/recognized-sports\",\n",
    "        \"crowdflower/sports-illustrated-covers\",\n",
    "        \"the-pudding/winningest-cities-in-sports\",\n",
    "        \"datagov-uk/17c44e3a-804c-487b-a07f-b90298685e2a\",\n",
    "        \"zendoll27/trends-in-youth-sports\"]\n",
    "\n",
    "    combined_metadata = []\n",
    "    columns = set()\n",
    "\n",
    "    for DataSet_URL in dataset_urls:\n",
    "        # Extracting the Metadata for dataset inputed \n",
    "        metadata = Fetch_MetaData(DataSet_URL)\n",
    "\n",
    "        if metadata:\n",
    "            combined_metadata.append(metadata)\n",
    "            columns.update(metadata.keys())\n",
    "\n",
    "            print(f\"Metadata retrieved for {DataSet_URL}.\")\n",
    "        else:\n",
    "            print(f\"Failed to retrieve dataset metadata for {DataSet_URL}.\")\n",
    "\n",
    "    # Fill missing columns with spaces\n",
    "    for metadata in combined_metadata:\n",
    "        for column in columns:\n",
    "            metadata.setdefault(column, ' ')\n",
    "\n",
    "    # Convert the combined metadata into a DataFrame\n",
    "    combined_metadata_df = pd.DataFrame(combined_metadata)\n",
    "\n",
    "    combined_metadata_df['dataset_url'] = \"https://data.world/\" + combined_metadata_df['owner'] + '/' + combined_metadata_df['id']\n",
    "    # Export combined metadata DataFrame to CSV file\n",
    "    combined_metadata_df.to_csv(\"MetaData_DataSet.csv\", index=False)\n",
    "\n",
    "    print(\"Combined metadata saved to combined_dataset_metadata.csv successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata retrieved for hdx/80ded4e2-aa4f-42bc-ad08-6c1effc24123.\n",
      "Metadata retrieved for hdx/f92954dc-3f5b-407a-80a9-1e178280b0d7.\n",
      "Metadata retrieved for us-hhs-gov/87c842cf-095a-412e-8cf2-5d87ed07e34b.\n",
      "Metadata retrieved for alexandra/food-related-words.\n",
      "Metadata retrieved for chhs/0114f5bb-4975-419d-95d9-5f0179a8de06.\n",
      "Combined metadata saved to combined_dataset_metadata.csv successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def Fetch_MetaData(DataSet_URL):\n",
    "    # Providing the API URL to \n",
    "    api_url = f\"https://api.data.world/v0/datasets/{DataSet_URL}\"\n",
    "    \n",
    "    # Set the generated API Key to read the metadata\n",
    "    api_token = \"eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OnN0ZWZmaTEwc2luZ2giLCJpc3MiOiJhZ2VudDpzdGVmZmkxMHNpbmdoOjo4ZDJkMjQ4MC04NzMxLTRmM2MtYTc3Mi1mN2FiZTNlNzUyOTUiLCJpYXQiOjE3MTE3MTIwODksInJvbGUiOlsidXNlcl9hcGlfcmVhZCIsInVzZXJfYXBpX3dyaXRlIl0sImdlbmVyYWwtcHVycG9zZSI6dHJ1ZSwic2FtbCI6e319.TC0Hk6lASv4bzo3_RThoQ1rLXYbnXNeT6xDGyg2WYfNKim53FQu7G4-4TsSbvSDtt0AQfKRgMVvL5JCHe454jQ\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_token}\"\n",
    "    }\n",
    "    \n",
    "    # Get request for API end point\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Fetching the Metadata\n",
    "        metadata = response.json()\n",
    "        return metadata\n",
    "    else:\n",
    "        print(f\"Failed to retrieve metadata for dataset: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # Inputing the dataset urls\n",
    "    dataset_urls = [\n",
    "        # CoronaVirus\n",
    "        \"hdx/80ded4e2-aa4f-42bc-ad08-6c1effc24123\",\n",
    "        \"hdx/f92954dc-3f5b-407a-80a9-1e178280b0d7\",\n",
    "        \"us-hhs-gov/87c842cf-095a-412e-8cf2-5d87ed07e34b\",\n",
    "        # Food\n",
    "        \"alexandra/food-related-words\",\n",
    "        \"chhs/0114f5bb-4975-419d-95d9-5f0179a8de06\"\n",
    "        ]\n",
    "\n",
    "    combined_metadata = []\n",
    "    columns = set()\n",
    "\n",
    "    for DataSet_URL in dataset_urls:\n",
    "        # Extracting the Metadata for dataset inputed \n",
    "        metadata = Fetch_MetaData(DataSet_URL)\n",
    "\n",
    "        if metadata:\n",
    "            combined_metadata.append(metadata)\n",
    "            columns.update(metadata.keys())\n",
    "\n",
    "            print(f\"Metadata retrieved for {DataSet_URL}.\")\n",
    "        else:\n",
    "            print(f\"Failed to retrieve dataset metadata for {DataSet_URL}.\")\n",
    "\n",
    "    # Fill missing columns with spaces\n",
    "    for metadata in combined_metadata:\n",
    "        for column in columns:\n",
    "            metadata.setdefault(column, ' ')\n",
    "\n",
    "    # Convert the combined metadata into a DataFrame\n",
    "    combined_metadata_df = pd.DataFrame(combined_metadata)\n",
    "\n",
    "    combined_metadata_df['dataset_url'] = \"https://data.world/\" + combined_metadata_df['owner'] + '/' + combined_metadata_df['id']\n",
    "    # Export combined metadata DataFrame to CSV file\n",
    "    combined_metadata_df.to_csv(\"New_MetaData_DataSet.csv\", index=False)\n",
    "\n",
    "    print(\"Combined metadata saved to combined_dataset_metadata.csv successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
